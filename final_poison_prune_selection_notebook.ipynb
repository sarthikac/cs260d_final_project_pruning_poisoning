{"cells":[{"cell_type":"markdown","id":"310c5236","metadata":{"id":"310c5236"},"source":["# Final Notebook: Poisoning, Data Selection, and Pruning\n","**Comparing:** Full data, Random subset, EL2N, Forgettability, and CRAIG-approx selection methods.\n","\n","This notebook runs prototype experiments on CIFAR-10 with label-flip and backdoor poisons, computes\n","attack success rate (ASR), poison retention, clean accuracy, and shows comparison plots.\n","\n","**Usage:** Set `PROTOTYPE = True` for quick runs on Colab/GPU. For final experiments, set `PROTOTYPE=False` and\n","increase epochs and repetitions.\n"]},{"cell_type":"code","execution_count":1,"id":"ff7684a1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11342,"status":"ok","timestamp":1764186540319,"user":{"displayName":"Demetri Nicolaou","userId":"06868073424147917136"},"user_tz":420},"id":"ff7684a1","outputId":"f66020a7-f339-4fc4-e880-a744ce43986b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n"]}],"source":["# -------------------------\n","# Setup: installs, imports, reproducibility\n","# -------------------------\n","PROTOTYPE = False  # set False for full experiments\n","\n","# Install optional packages if missing (scikit-learn, tqdm)\n","try:\n","    import sklearn, tqdm\n","except Exception:\n","    import sys, subprocess\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"scikit-learn\", \"tqdm\"])\n","\n","import os, random, time, copy, math\n","from pathlib import Path\n","import numpy as np\n","import torch, torch.nn as nn, torch.optim as optim\n","from torch.utils.data import DataLoader, Subset\n","import torchvision, torchvision.transforms as transforms\n","from torchvision.models import resnet18\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans\n","import pandas as pd\n","\n","# Seed for reproducibility\n","seed = 0\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","torch.backends.cudnn.benchmark = True\n","\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","elif torch.backends.mps.is_available():\n","    device = torch.device('mps')\n","else:\n","    device = torch.device('cpu')\n","print('Device:', device)"]},{"cell_type":"code","execution_count":2,"id":"9edd0db7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18648,"status":"ok","timestamp":1764186558990,"user":{"displayName":"Demetri Nicolaou","userId":"06868073424147917136"},"user_tz":420},"id":"9edd0db7","outputId":"1ac7d0eb-5c0d-442e-bda6-4bc757925bf1"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 170M/170M [00:13<00:00, 12.2MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loaded CIFAR-10: train size 50000 test size 10000\n"]}],"source":["# -------------------------\n","# Data transforms & load CIFAR-10\n","# -------------------------\n","if PROTOTYPE:\n","    train_epochs = 8\n","    batch_size = 128\n","    subset_frac = 0.25\n","    el2n_epochs = 2\n","    forget_epochs = 3\n","else:\n","    train_epochs = 50\n","    batch_size = 128\n","    subset_frac = 0.5\n","    el2n_epochs = 5\n","    forget_epochs = 10\n","\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465),(0.2470, 0.2435, 0.2616)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465),(0.2470, 0.2435, 0.2616)),\n","])\n","\n","data_root = './data'\n","train_set = torchvision.datasets.CIFAR10(root=data_root, train=True, download=True, transform=transform_train)\n","test_set  = torchvision.datasets.CIFAR10(root=data_root, train=False, download=True, transform=transform_test)\n","\n","num_workers = 0\n","train_loader_full = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n","test_loader = DataLoader(test_set, batch_size=256, shuffle=False, num_workers=num_workers, pin_memory=True)\n","print('Loaded CIFAR-10: train size', len(train_set), 'test size', len(test_set))"]},{"cell_type":"code","execution_count":3,"id":"e21a1a70","metadata":{"executionInfo":{"elapsed":34,"status":"ok","timestamp":1764186559075,"user":{"displayName":"Demetri Nicolaou","userId":"06868073424147917136"},"user_tz":420},"id":"e21a1a70"},"outputs":[],"source":["# Generate poisons. There are two approaches: backdoor and label flip\n","\n","import copy\n","from PIL import Image, ImageDraw\n","\n","def make_label_flip_dataset(orig_dataset, fraction=0.01, source_class=0, target_class=1, seed=0):\n","    \"\"\"\n","    Returns (copied_dataset, set_of_poisoned_indices)\n","    \"\"\"\n","    random.seed(seed)\n","    ds = copy.deepcopy(orig_dataset)\n","    indices = [i for i,l in enumerate(ds.targets) if l==source_class]\n","    n_poison = max(1, int(len(indices) * fraction))\n","    poisoned_idx = random.sample(indices, n_poison)\n","    for i in poisoned_idx:\n","        ds.targets[i] = target_class\n","    return ds, set(poisoned_idx)\n","\n","class BackdoorDataset(torchvision.datasets.CIFAR10):\n","    def __init__(self, *args, poison_frac=0.01, patch_size=6, source_class=None, target_class=0, seed=0, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.poison_frac = poison_frac\n","        self.patch_size = patch_size\n","        self.source_class = source_class\n","        self.target_class = target_class\n","        self.seed = seed\n","        random.seed(seed)\n","        if source_class is None:\n","            all_idx = list(range(len(self)))\n","            n_poison = max(1, int(len(all_idx) * poison_frac))\n","            self.poisoned_idx = set(random.sample(all_idx, n_poison))\n","        else:\n","            indices = [i for i,l in enumerate(self.targets) if l==source_class]\n","            n_poison = max(1, int(len(indices) * poison_frac))\n","            self.poisoned_idx = set(random.sample(indices, n_poison))\n","\n","    def __getitem__(self, index):\n","        img, target = super().__getitem__(index)\n","        if index in self.poisoned_idx:\n","            raw = Image.fromarray(self.data[index])\n","            draw = ImageDraw.Draw(raw)\n","            w,h = raw.size\n","            ps = self.patch_size\n","            box = (w-ps-1, h-ps-1, w-1, h-1)\n","            draw.rectangle(box, fill=(255,0,0))\n","            if self.transform is not None:\n","                img = self.transform(raw)\n","            else:\n","                img = transforms.ToTensor()(raw)\n","            target = self.target_class\n","        return img, target"]},{"cell_type":"code","execution_count":4,"id":"02826247","metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1764186559139,"user":{"displayName":"Demetri Nicolaou","userId":"06868073424147917136"},"user_tz":420},"id":"02826247"},"outputs":[],"source":["# -------------------------\n","# Model wrapper: ResNet18 model that works on CIFAR-10 images\n","# (handles smaller inputs than image net images and 10 classes)\n","# -------------------------\n","class ResNet18Wrapper(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super().__init__()\n","        base = resnet18(weights=None)\n","\n","        # 1. Modify the initial layers for small images (e.g., CIFAR)\n","        # Change 7x7 Conv (stride 2) to 3x3 Conv (stride 1)\n","        base.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","\n","        self.features = nn.Sequential(\n","            base.conv1,\n","            base.bn1,\n","            base.relu,\n","            base.layer1,\n","            base.layer2,\n","            base.layer3,\n","            base.layer4,\n","            base.avgpool\n","        )\n","\n","        feat_dim = base.fc.in_features\n","        self.classifier = nn.Linear(feat_dim, num_classes)\n","        nn.init.normal_(self.classifier.weight, 0, 0.01)\n","        nn.init.constant_(self.classifier.bias, 0.0)\n","\n","    def forward(self, x):\n","        f = self.features(x)\n","        f = torch.flatten(f, 1)\n","        return self.classifier(f)\n","\n","def get_model(num_classes=10):\n","    return ResNet18Wrapper(num_classes=num_classes).to(device)"]},{"cell_type":"code","execution_count":5,"id":"2302057d","metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1764186559204,"user":{"displayName":"Demetri Nicolaou","userId":"06868073424147917136"},"user_tz":420},"id":"2302057d"},"outputs":[],"source":["# -------------------------\n","# Training / evaluation utilities\n","# -------------------------\n","def train_one_epoch(model, loader, optimizer, criterion, desc=''):\n","    model.train()\n","    running_loss = 0.0; correct = 0; total = 0\n","    for inputs, targets in tqdm(loader, desc=desc, leave=False):\n","        inputs = inputs.to(device); targets = targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward(); optimizer.step()\n","        running_loss += loss.item() * inputs.size(0)\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0); correct += predicted.eq(targets).sum().item()\n","    return running_loss/total, correct/total\n","\n","def evaluate(model, loader):\n","    model.eval()\n","    total=0; correct=0; losses=0.0\n","    criterion = nn.CrossEntropyLoss(reduction='sum')\n","    with torch.no_grad():\n","        for inputs, targets in loader:\n","            inputs = inputs.to(device); targets = targets.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","            losses += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0); correct += predicted.eq(targets).sum().item()\n","    return losses/total, correct/total\n","\n","def predict_logits(model, loader):\n","    model.eval()\n","    logits_list = []; targets_list = []\n","    with torch.no_grad():\n","        for inputs, targets in loader:\n","            inputs = inputs.to(device)\n","            logits = model(inputs)\n","            logits_list.append(logits.cpu()); targets_list.append(targets)\n","    return torch.cat(logits_list), torch.cat(targets_list)\n"]},{"cell_type":"code","execution_count":6,"id":"1518fbfb","metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1764186559269,"user":{"displayName":"Demetri Nicolaou","userId":"06868073424147917136"},"user_tz":420},"id":"1518fbfb"},"outputs":[],"source":["# -------------------------\n","# EL2N and Forgetting scores\n","# -------------------------\n","def compute_el2n(model_fn, dataset, epochs=3, batch_size=256):\n","    model = model_fn().to(device)\n","    opt = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n","    scheduler = optim.lr_scheduler.StepLR(opt, step_size=2, gamma=0.1)\n","    criterion = nn.CrossEntropyLoss()\n","    el2n = np.zeros(len(dataset))\n","    loader_train = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=num_workers)\n","    for e in range(epochs):\n","        print('EL2N train epoch', e+1)\n","        train_one_epoch(model, loader_train, opt, criterion, desc=f'EL2N-{e}')\n","        scheduler.step()\n","        idx = 0\n","        model.eval()\n","        with torch.no_grad():\n","            for inputs, targets in DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers):\n","                inputs = inputs.to(device)\n","                logits = model(inputs).cpu().numpy()\n","                bs = logits.shape[0]\n","                for i in range(bs):\n","                    lab = np.zeros(logits.shape[1]); lab[targets[i]] = 1.0\n","                    el2n[idx+i] += np.linalg.norm(logits[i] - lab)\n","                idx += bs\n","    el2n = el2n / epochs\n","    return el2n\n","\n","def compute_forgetting_scores(model_fn, dataset, epochs=5, batch_size=256):\n","    model = model_fn().to(device)\n","    opt = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n","    scheduler = optim.lr_scheduler.StepLR(opt, step_size=3, gamma=0.1)\n","    criterion = nn.CrossEntropyLoss()\n","    n = len(dataset)\n","    correct_counts = np.zeros(n, dtype=int)\n","    for e in range(epochs):\n","        print('Forgetting training epoch', e+1)\n","        train_one_epoch(model, DataLoader(dataset, batch_size=128, shuffle=True, num_workers=num_workers), opt, criterion, desc=f'Forget-{e}')\n","        scheduler.step()\n","        idx = 0\n","        model.eval()\n","        with torch.no_grad():\n","            for inputs, targets in DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers):\n","                inputs = inputs.to(device)\n","                outputs = model(inputs).cpu().numpy()\n","                preds = outputs.argmax(axis=1)\n","                bs = len(preds)\n","                for i in range(bs):\n","                    if preds[i] == targets.numpy()[i]:\n","                        correct_counts[idx+i] += 1\n","                idx += bs\n","    forgetting = epochs - correct_counts\n","    return forgetting"]},{"cell_type":"code","execution_count":7,"id":"c383148b","metadata":{"executionInfo":{"elapsed":77,"status":"ok","timestamp":1764186559378,"user":{"displayName":"Demetri Nicolaou","userId":"06868073424147917136"},"user_tz":420},"id":"c383148b"},"outputs":[],"source":["# -------------------------\n","# CRAIG: last-layer gradient embeddings + facility-location greedy\n","# -------------------------\n","import torch.nn.functional as F\n","\n","def get_last_layer_grads_wrapper(model, dataset, batch_size=256):\n","    \"\"\"\n","    Returns numpy array shape (N, D) of last-layer gradient embeddings\n","    for every example in dataset. The dataset is assumed to be ordered\n","    so index i corresponds to embeddings[i].\n","    \"\"\"\n","    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","    model.eval()\n","    embeddings = []\n","    with torch.no_grad():\n","        for imgs, labels in loader:\n","            imgs = imgs.to(device); labels = labels.to(device)\n","            feats = model.features(imgs)           # (B, C, 1, 1)\n","            feats = torch.flatten(feats, 1)        # (B, feat_dim)\n","            logits = model.classifier(feats)       # (B, num_classes)\n","            probs = torch.softmax(logits, dim=1)\n","            y_onehot = torch.zeros_like(probs)\n","            y_onehot[torch.arange(len(labels)), labels] = 1.0\n","            diff = (probs - y_onehot)              # (B, num_classes)\n","            emb = torch.einsum('bc,bd->bcd', diff, feats).reshape(len(labels), -1)  # (B, num_classes * feat_dim)\n","            embeddings.append(emb.cpu())\n","    embeddings = torch.cat(embeddings, dim=0)  # (N, D)\n","    return embeddings.numpy()\n","\n","def facility_location_greedy(embeddings, k):\n","    \"\"\"\n","    Facility-location greedy selection on normalized embeddings.\n","    embeddings: (N, D) numpy\n","    returns: selected indices (list)\n","    \"\"\"\n","    N = embeddings.shape[0]\n","    # normalize for numerical stability\n","    norms = np.linalg.norm(embeddings, axis=1, keepdims=True) + 1e-10\n","    E = embeddings / norms\n","    S = E @ E.T  # similarity matrix, shape (N, N)\n","    selected = []\n","    max_sim = np.zeros(N)   # current best similarity of each point to any selected so far\n","    for _ in range(k):\n","        # gain of picking candidate i = sum( max( S[i,:], max_sim ) - max_sim )\n","        # compute approximate marginal gains by checking S.max - max_sim\n","        gains = S.max(axis=0) - max_sim   # cheap approx\n","        idx = int(np.argmax(gains))\n","        selected.append(idx)\n","        max_sim = np.maximum(max_sim, S[idx])\n","    return selected\n","\n","def select_subset_craig(model_fn, full_dataset, subset_size, batch_size=256):\n","    \"\"\"\n","    model_fn: function returning a fresh model instance (so embeddings computed on fresh model)\n","    full_dataset: dataset to select from (ordered)\n","    subset_size: int\n","    \"\"\"\n","    model = model_fn().to(device)\n","    print('Computing CRAIG embeddings (last-layer grads)...')\n","    emb = get_last_layer_grads_wrapper(model, full_dataset, batch_size=batch_size)\n","    print('Selecting with facility-location greedy ...')\n","    sel = facility_location_greedy(emb, subset_size)\n","    print(f'CRAIG selected {len(sel)} items.')\n","    return sel"]},{"cell_type":"code","execution_count":8,"id":"hytHhwXx4M1M","metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1764186559442,"user":{"displayName":"Demetri Nicolaou","userId":"06868073424147917136"},"user_tz":420},"id":"hytHhwXx4M1M"},"outputs":[],"source":["import torch\n","from torch.utils.data import Subset\n","\n","def distributed_greedy_craig(model_fn, full_dataset, subset_size, partitions=5, batch_size=256):\n","    print(f'Distributed CRAIG: dataset size {len(full_dataset)}, partitions {partitions}, total subset size {subset_size}')\n","\n","    partition_size = len(full_dataset) // partitions\n","    local_subsets = []\n","    local_k = subset_size // partitions\n","\n","    for i in range(partitions):\n","        start = i * partition_size\n","        end = (i + 1) * partition_size if i < partitions - 1 else len(full_dataset)\n","        local_indices = list(range(start, end))\n","        local_data = Subset(full_dataset, local_indices)\n","\n","        print(f'Partition {i+1}/{partitions}: computing embeddings for {len(local_data)} samples...')\n","        model = model_fn().to(device)\n","        emb = get_last_layer_grads_wrapper(model, local_data, batch_size=batch_size)\n","\n","        print(f'Partition {i+1}/{partitions}: running facility-location greedy selection for {local_k} samples...')\n","        local_sel = facility_location_greedy(emb, local_k)\n","\n","        local_sel_global = [local_indices[idx] for idx in local_sel]\n","        local_subsets.extend(local_sel_global)\n","\n","    print(f'Final selection: computing embeddings for combined local subset of size {len(local_subsets)}...')\n","    combined_data = Subset(full_dataset, local_subsets)\n","    model = model_fn().to(device)\n","    emb = get_last_layer_grads_wrapper(model, combined_data, batch_size=batch_size)\n","\n","    print(f'Final selection: running facility-location greedy for final {subset_size} samples...')\n","    final_sel_local = facility_location_greedy(emb, subset_size)\n","\n","    final_sel_global = [local_subsets[idx] for idx in final_sel_local]\n","    print(f'Distributed CRAIG finished selecting {len(final_sel_global)} samples.')\n","\n","    return final_sel_global\n"]},{"cell_type":"code","execution_count":9,"id":"b60ccd66","metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1764186559514,"user":{"displayName":"Demetri Nicolaou","userId":"06868073424147917136"},"user_tz":420},"id":"b60ccd66"},"outputs":[],"source":["# -------------------------\n","# Subset helpers and metrics: ASR, retention\n","# -------------------------\n","def subset_from_indices(dataset, indices):\n","    return Subset(dataset, indices)\n","\n","def sample_random_indices(dataset, k, seed=0):\n","    random.seed(seed); idxs = list(range(len(dataset))); return random.sample(idxs, k)\n","\n","def compute_poison_retention(poisoned_idx_set, subset_indices):\n","    kept = sum([1 for i in subset_indices if i in poisoned_idx_set])\n","    return kept, len(poisoned_idx_set), kept / max(1, len(poisoned_idx_set))\n","\n","def compute_backdoor_asr(model, test_loader, trigger_patch_size=6, target_label=0):\n","    model.eval(); total=0; succ=0\n","    mean = torch.tensor((0.4914, 0.4822, 0.4465)).view(1,3,1,1).to(device)\n","    std  = torch.tensor((0.2470, 0.2435, 0.2616)).view(1,3,1,1).to(device)\n","    with torch.no_grad():\n","        for inputs, targets in test_loader:\n","            imgs = inputs.clone().to(device)\n","            imgs = imgs * std + mean\n","            imgs[:, :, (32-trigger_patch_size):, (32-trigger_patch_size):] = torch.tensor([1.0, 0.0, 0.0]).view(1,3,1,1).to(device)\n","            imgs = (imgs - mean) / std\n","            outputs = model(imgs)\n","            preds = outputs.argmax(dim=1).cpu().numpy()\n","            total += len(preds)\n","            succ += (preds == target_label).sum().item()\n","    return succ / total\n","\n","def compute_labelflip_asr(model, test_loader, source_label=0, target_label=1):\n","    model.eval(); total=0; succ=0\n","    with torch.no_grad():\n","        for inputs, targets in test_loader:\n","            mask = (targets == source_label)\n","            if mask.sum() == 0: continue\n","            batch = inputs[mask].to(device)\n","            outputs = model(batch)\n","            preds = outputs.argmax(dim=1).cpu().numpy()\n","            total += len(preds)\n","            succ += (preds == target_label).sum().item()\n","    return succ / total if total>0 else 0.0"]},{"cell_type":"code","execution_count":10,"id":"694ad81c","metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1764186559579,"user":{"displayName":"Demetri Nicolaou","userId":"06868073424147917136"},"user_tz":420},"id":"694ad81c"},"outputs":[],"source":["# -------------------------\n","# Pruning utilities (IMP) with rewind\n","# -------------------------\n","def get_prunable_layers(model):\n","    \"\"\"Returns list of (name, module) for valid prunable layers (Conv2d, Linear).\"\"\"\n","    valid_layers = []\n","    for name, m in model.named_modules():\n","        if isinstance(m, (nn.Conv2d, nn.Linear)):\n","            valid_layers.append((name, m))\n","    return valid_layers\n","\n","def prune_by_percentile(model, amount):\n","    \"\"\"Layer-wise pruning to ensure connectivity and ignore BN/Biases.\"\"\"\n","    mask = {}\n","    valid_layers = get_prunable_layers(model)\n","\n","    for name, m in valid_layers:\n","        # Calculate threshold for THIS layer only\n","        weights = m.weight.data.abs().cpu().numpy()\n","        threshold = np.quantile(weights, amount)\n","\n","        # Create mask for weight only (ignore bias)\n","        mask[name + '.weight'] = (m.weight.data.abs() > threshold).float().to(device)\n","\n","    return mask\n","\n","def apply_mask(model, mask):\n","    \"\"\"Applies mask to model weights.\"\"\"\n","    for name, p in model.named_parameters():\n","        if name in mask:\n","            p.data.mul_(mask[name])\n","\n","def iterative_magnitude_prune_and_retrain(model_fn, train_dataset, test_loader,\n","                                            fraction_to_prune=0.2, iterations=2,\n","                                            rewind_epoch=1, epochs_per_cycle=3):\n","    model = model_fn().to(device)\n","    opt = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n","    crit = nn.CrossEntropyLoss()\n","\n","    # 1. Train to rewind point\n","    print(f\"Training to rewind epoch {rewind_epoch}...\")\n","    for e in range(rewind_epoch):\n","        train_one_epoch(model, DataLoader(train_dataset, batch_size=batch_size, shuffle=True), opt, crit)\n","\n","    rewind_state = copy.deepcopy(model.state_dict())\n","    mask = None\n","\n","    for it in range(iterations):\n","        print(f\"Pruning iteration {it+1}/{iterations}...\")\n","\n","        mask = prune_by_percentile(model, fraction_to_prune)\n","\n","        # Rewind weights, re-initialize training optimizer and scheduler for\n","        # re-training.\n","        model.load_state_dict(rewind_state)\n","        apply_mask(model, mask)\n","\n","        opt = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n","        scheduler = optim.lr_scheduler.StepLR(opt, step_size=epochs_per_cycle//2, gamma=0.1)\n","\n","        # Retrain with mask enforcement\n","        for e in range(epochs_per_cycle):\n","            model.train()\n","\n","            for inputs, targets in DataLoader(train_dataset, batch_size=batch_size, shuffle=True):\n","                inputs, targets = inputs.to(device), targets.to(device)\n","                opt.zero_grad()\n","                outputs = model(inputs)\n","                loss = crit(outputs, targets)\n","                loss.backward()\n","                opt.step()\n","\n","                apply_mask(model, mask)\n","\n","            scheduler.step()\n","\n","    return model, mask"]},{"cell_type":"code","execution_count":11,"id":"94e102d6","metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1764186559643,"user":{"displayName":"Demetri Nicolaou","userId":"06868073424147917136"},"user_tz":420},"id":"94e102d6"},"outputs":[],"source":["# -------------------------\n","# Orchestrate all methods and evaluate\n","# -------------------------\n","def run_all_methods(poison_type='backdoor', poison_frac=0.02, subset_frac=0.25, selection_methods=None):\n","    if selection_methods is None:\n","        selection_methods = ['full', 'random', 'el2n', 'forget', 'craig_dist']\n","    results = {}\n","    # prepare poisoned dataset\n","    if poison_type == 'label_flip':\n","        ds_poisoned, poisoned_idx = make_label_flip_dataset(train_set, fraction=poison_frac, source_class=0, target_class=1, seed=seed)\n","        poisoned_set = poisoned_idx\n","    elif poison_type == 'backdoor':\n","        ds_poisoned = BackdoorDataset(root=data_root, train=True, download=False, transform=transform_train,\n","                                     poison_frac=poison_frac, patch_size=6, source_class=None, target_class=0, seed=seed)\n","        poisoned_set = ds_poisoned.poisoned_idx\n","    else:\n","        raise ValueError('Unknown poison type')\n","    n = len(ds_poisoned); k = int(n * subset_frac)\n","    print(f'Running poison_type={poison_type}, poison_frac={poison_frac}, subset size {k} (of {n})')\n","    for method in selection_methods:\n","        print('\\n---- Selection method:', method, '----')\n","        if method == 'full':\n","            indices = list(range(n))\n","        elif method == 'random':\n","            indices = sample_random_indices(ds_poisoned, k, seed=seed)\n","        elif method == 'el2n':\n","            scores = compute_el2n(lambda: get_model(), ds_poisoned, epochs=el2n_epochs)\n","            idx_sorted = np.argsort(-scores)  # keep hardest\n","            indices = idx_sorted[:k].tolist()\n","        elif method == 'forget':\n","            scores = compute_forgetting_scores(lambda: get_model(), ds_poisoned, epochs=forget_epochs)\n","            idx_sorted = np.argsort(-scores)\n","            indices = idx_sorted[:k].tolist()\n","        elif method == 'craig_dist':\n","            indices = distributed_greedy_craig(\n","                model_fn=lambda: get_model(),\n","                full_dataset=ds_poisoned,\n","                subset_size=k,\n","                partitions=5,\n","                batch_size=256\n","            )\n","        elif method == 'craig':\n","            indices = select_subset_craig(lambda: get_model(), ds_poisoned, subset_size=k, batch_size=256)\n","        else:\n","            raise ValueError('Unknown method ' + method)\n","        subset = subset_from_indices(ds_poisoned, indices)\n","        # train model on subset\n","        model = get_model()\n","        opt = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n","        scheduler = optim.lr_scheduler.MultiStepLR(opt, milestones=[30, 40], gamma=0.1)\n","        crit = nn.CrossEntropyLoss()\n","        for e in range(train_epochs):\n","            train_one_epoch(model, DataLoader(subset, batch_size=batch_size, shuffle=True, num_workers=num_workers), opt, crit, desc=f'{method}-Train-E{e}')\n","            scheduler.step()\n","        loss, acc = evaluate(model, test_loader)\n","        print('Clean test acc after training on subset:', acc)\n","        # compute ASR\n","        if poison_type == 'backdoor':\n","            asr = compute_backdoor_asr(model, test_loader, trigger_patch_size=6, target_label=0)\n","        else:\n","            asr = compute_labelflip_asr(model, test_loader, source_label=0, target_label=1)\n","        kept, total_poison, retention = compute_poison_retention(poisoned_set, indices)\n","        print(f'Kept poisoned examples in subset: {kept}/{total_poison} ({retention*100:.2f}%)')\n","        print('ASR (attack success rate):', asr)\n","\n","        # prune & evaluate. We will rewind back\n","        pruned_model, mask = iterative_magnitude_prune_and_retrain(\n","            lambda: get_model(),\n","            subset,\n","            test_loader,\n","            fraction_to_prune=0.3,\n","            iterations=2,\n","            rewind_epoch=1,\n","            epochs_per_cycle=15\n","        )\n","\n","        ploss, pacc = evaluate(pruned_model, test_loader)\n","        if poison_type == 'backdoor':\n","            pasr = compute_backdoor_asr(pruned_model, test_loader, trigger_patch_size=6, target_label=0)\n","        else:\n","            pasr = compute_labelflip_asr(pruned_model, test_loader, source_label=0, target_label=1)\n","        print('Pruned model acc:', pacc, 'Pruned ASR:', pasr)\n","        results[method] = {'subset_size': len(indices),\n","                           'clean_acc': acc,\n","                           'asr': asr,\n","                           'poison_kept': kept,\n","                           'poison_total': total_poison,\n","                           'poison_retention': retention,\n","                           'pruned_acc': pacc,\n","                           'pruned_asr': pasr}\n","    return results"]},{"cell_type":"code","execution_count":12,"id":"69a68f48","metadata":{"executionInfo":{"elapsed":41,"status":"ok","timestamp":1764186559723,"user":{"displayName":"Demetri Nicolaou","userId":"06868073424147917136"},"user_tz":420},"id":"69a68f48"},"outputs":[],"source":["# -------------------------\n","# Plotting and CSV save helpers\n","# -------------------------\n","def plot_results(results, title='Results'):\n","    methods = list(results.keys())\n","    clean = [results[m]['clean_acc'] for m in methods]\n","    asr = [results[m]['asr'] for m in methods]\n","    retention = [results[m]['poison_retention'] for m in methods]\n","    pruned_acc = [results[m]['pruned_acc'] for m in methods]\n","    pruned_asr = [results[m]['pruned_asr'] for m in methods]\n","\n","    x = np.arange(len(methods))\n","    width = 0.28\n","    plt.figure(figsize=(12,5))\n","    plt.subplot(1,2,1)\n","    plt.bar(x - width, clean, width, label='Clean Acc')\n","    plt.bar(x, pruned_acc, width, label='Pruned Acc')\n","    plt.xticks(x, methods, rotation=30)\n","    plt.ylabel('Accuracy'); plt.ylim(0,1); plt.legend()\n","    plt.title('Clean Acc (Dense vs Pruned)')\n","\n","    plt.subplot(1,2,2)\n","    plt.bar(x - width, asr, width, label='ASR (dense)')\n","    plt.bar(x, pruned_asr, width, label='ASR (pruned)')\n","    plt.xticks(x, methods, rotation=30)\n","    plt.ylabel('Attack Success Rate'); plt.ylim(0,1); plt.legend()\n","    plt.title('Attack Success Rate (Dense vs Pruned)')\n","    plt.suptitle(title)\n","    plt.tight_layout(rect=[0,0,1,0.95])\n","    plt.show()\n","\n","    plt.figure(figsize=(6,3))\n","    plt.bar(methods, retention)\n","    plt.title('Poison Retention Fraction in Selected Subsets')\n","    plt.ylim(0,1)\n","    plt.show()\n","\n","def save_results_csv(results, fname='results_summary.csv'):\n","    rows = []\n","    for m,v in results.items():\n","        r = {'method': m}\n","        r.update(v)\n","        rows.append(r)\n","    df = pd.DataFrame(rows)\n","    df.to_csv(fname, index=False)\n","    print('Saved results to', fname)"]},{"cell_type":"code","source":["    selection_methods = ['full', 'random', 'el2n', 'forget', 'craig_dist']"],"metadata":{"id":"XLrWpYsvhQHX","executionInfo":{"status":"ok","timestamp":1764186559806,"user_tz":420,"elapsed":42,"user":{"displayName":"Demetri Nicolaou","userId":"06868073424147917136"}}},"id":"XLrWpYsvhQHX","execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"KnxkTZGgmYsD","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KnxkTZGgmYsD","outputId":"2c5f8980-36cb-4b76-b96e-ccfc108a2729"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running poison_type=backdoor, poison_frac=0.02, subset size 25000 (of 50000)\n","\n","---- Selection method: full ----\n"]},{"output_type":"stream","name":"stderr","text":["full-Train-E45:  86%|████████▋ | 338/391 [00:22<00:03, 15.13it/s]"]}],"source":["    # Backdoor experiment\n","    res_backdoor = run_all_methods(poison_type='backdoor', poison_frac=0.02, subset_frac=subset_frac, selection_methods=selection_methods)\n","    print('\\nBackdoor results:'); print(res_backdoor)\n","    save_results_csv(res_backdoor, fname='backdoor_results_prototype.csv')"]},{"cell_type":"code","execution_count":null,"id":"lGFlbDp-md5K","metadata":{"id":"lGFlbDp-md5K"},"outputs":[],"source":["    plot_results(res_backdoor, title='Backdoor Poisoning Results (Prototype)')"]},{"cell_type":"code","execution_count":null,"id":"PXLr7M0mmfIT","metadata":{"id":"PXLr7M0mmfIT"},"outputs":[],"source":["    res_labelflip = run_all_methods(poison_type='label_flip', poison_frac=0.02, subset_frac=subset_frac, selection_methods=selection_methods)\n","    print('\\nLabel-flip results:'); print(res_labelflip)\n","    save_results_csv(res_labelflip, fname='labelflip_results_prototype.csv')"]},{"cell_type":"code","execution_count":null,"id":"P7WkCYr9mjLQ","metadata":{"id":"P7WkCYr9mjLQ"},"outputs":[],"source":["    plot_results(res_labelflip, title='Label-Flip Poisoning Results (Prototype)')"]},{"cell_type":"markdown","id":"25afbdca","metadata":{"id":"25afbdca"},"source":["## Notes & next steps\n","\n","- For final experiments: set `PROTOTYPE=False`, increase `train_epochs`, `el2n_epochs`, and `forget_epochs`, and run multiple random seeds.\n","- Replace CRAIG-approx with the official CRAIG implementation (gradient-matching) for stronger comparisons (Done).\n","- Add more powerful poisoning attacks (gradient-matching poison) for robustness testing.\n","- Save results to CSV and run multiple seeds for statistical significance.\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[]},"kernelspec":{"display_name":"pytorch_m3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.16"}},"nbformat":4,"nbformat_minor":5}